{
	"info": {
		"_postman_id": "sre-inference-gateway-collection",
		"name": "SRE Inference Gateway API Tests",
		"description": "Comprehensive test collection for the SRE Inference Gateway API including OpenAI and vLLM providers",
		"schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json",
		"_exporter_id": "sre-gateway-tests"
	},
	"item": [
		{
			"name": "Health Checks",
			"item": [
				{
					"name": "Basic Health Check",
					"request": {
						"method": "GET",
						"header": [],
						"url": {
							"raw": "{{base_url}}/health",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"health"
							]
						}
					},
					"response": []
				},
				{
					"name": "Detailed Health Check",
					"request": {
						"method": "GET",
						"header": [],
						"url": {
							"raw": "{{base_url}}/health/detailed",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"health",
								"detailed"
							]
						}
					},
					"response": []
				},
				{
					"name": "Readiness Check",
					"request": {
						"method": "GET",
						"header": [],
						"url": {
							"raw": "{{base_url}}/ready",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"ready"
							]
						}
					},
					"response": []
				},
				{
					"name": "Provider Health Status",
					"request": {
						"method": "GET",
						"header": [],
						"url": {
							"raw": "{{base_url}}/health/providers",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"health",
								"providers"
							]
						}
					},
					"response": []
				},
				{
					"name": "Single Provider Health - OpenAI",
					"request": {
						"method": "GET",
						"header": [],
						"url": {
							"raw": "{{base_url}}/health/providers/openai",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"health",
								"providers",
								"openai"
							]
						}
					},
					"response": []
				},
				{
					"name": "Single Provider Health - vLLM",
					"request": {
						"method": "GET",
						"header": [],
						"url": {
							"raw": "{{base_url}}/health/providers/vllm",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"health",
								"providers",
								"vllm"
							]
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "System Endpoints",
			"item": [
				{
					"name": "Root Endpoint",
					"request": {
						"method": "GET",
						"header": [],
						"url": {
							"raw": "{{base_url}}/",
							"host": [
								"{{base_url}}"
							],
							"path": [
								""
							]
						}
					},
					"response": []
				},
				{
					"name": "Prometheus Metrics",
					"request": {
						"method": "GET",
						"header": [],
						"url": {
							"raw": "{{base_url}}/v1/metrics",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"metrics"
							]
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Chat Completions - Mock Providers",
			"item": [
				{
					"name": "Mock OpenAI - Simple Request",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"gpt-5-nano\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello! How are you?\"\n    }\n  ],\n  \"temperature\": 0.7,\n  \"max_tokens\": 100\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				},
				{
					"name": "Mock vLLM - Simple Request",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							},
							{
								"key": "X-Provider-Priority",
								"value": "mock_vllm"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"google/gemma-3-270m\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are a helpful assistant.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Explain quantum computing in simple terms.\"\n    }\n  ],\n  \"temperature\": 0.8,\n  \"max_tokens\": 200\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Chat Completions - OpenAI Provider",
			"item": [
				{
					"name": "OpenAI - GPT-5 Nano",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							},
							{
								"key": "X-Provider-Priority",
								"value": "openai"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"gpt-5-nano\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Write a short poem about artificial intelligence.\"\n    }\n  ],\n  \"temperature\": 0.7,\n  \"max_tokens\": 150\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				},
				{
					"name": "OpenAI - GPT-5 Nano",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							},
							{
								"key": "X-Provider-Priority",
								"value": "openai"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"gpt-5-nano\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are a helpful coding assistant.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Write a Python function to calculate the factorial of a number.\"\n    }\n  ],\n  \"temperature\": 0.3,\n  \"max_tokens\": 200\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				},
				{
					"name": "OpenAI - GPT-5 Nano",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							},
							{
								"key": "X-Provider-Priority",
								"value": "openai"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"gpt-5-nano\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Explain the differences between REST and GraphQL APIs.\"\n    }\n  ],\n  \"temperature\": 0.5,\n  \"max_tokens\": 300\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				},
				{
					"name": "OpenAI - Conversation with Context",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							},
							{
								"key": "X-Provider-Priority",
								"value": "openai"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"gpt-5-nano\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are a knowledgeable software architect.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"What are the key principles of microservices architecture?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"Microservices architecture is based on several key principles: 1) Single Responsibility - each service handles one business capability, 2) Decentralized - services manage their own data and business logic, 3) Fault Isolation - failure in one service doesn't cascade, 4) Technology Diversity - different services can use different tech stacks.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"How do you handle data consistency across microservices?\"\n    }\n  ],\n  \"temperature\": 0.6,\n  \"max_tokens\": 250\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Chat Completions - vLLM Provider",
			"item": [
				{
					"name": "vLLM - Llama 2 7B",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							},
							{
								"key": "X-Provider-Priority",
								"value": "vllm"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"google/gemma-3-270m\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"What are the benefits of using open-source language models?\"\n    }\n  ],\n  \"temperature\": 0.7,\n  \"max_tokens\": 200\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				},
				{
					"name": "vLLM - Code Generation",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							},
							{
								"key": "X-Provider-Priority",
								"value": "vllm"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"google/gemma-3-270m\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are a helpful coding assistant. Write clean, well-documented code.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Write a Python class for a simple bank account with deposit, withdraw, and balance methods.\"\n    }\n  ],\n  \"temperature\": 0.2,\n  \"max_tokens\": 300\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				},
				{
					"name": "vLLM - High Temperature Creative",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							},
							{
								"key": "X-Provider-Priority",
								"value": "vllm"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"google/gemma-3-270m\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Write a creative story about a robot learning to paint.\"\n    }\n  ],\n  \"temperature\": 1.2,\n  \"max_tokens\": 400,\n  \"top_p\": 0.9\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Parameter Testing",
			"item": [
				{
					"name": "All Parameters - OpenAI",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							},
							{
								"key": "X-Provider-Priority",
								"value": "openai"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"gpt-5-nano\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Generate a list of creative project names for a web development agency.\"\n    }\n  ],\n  \"temperature\": 0.9,\n  \"max_tokens\": 150,\n  \"top_p\": 0.95,\n  \"frequency_penalty\": 0.5,\n  \"presence_penalty\": 0.3,\n  \"user\": \"test-user-123\"\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				},
				{
					"name": "Minimal Parameters",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"gpt-5-nano\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello!\"\n    }\n  ]\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Error Testing",
			"item": [
				{
					"name": "Invalid Model",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							},
							{
								"key": "X-Provider-Priority",
								"value": "openai"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"invalid-model-name\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"This should fail.\"\n    }\n  ]\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				},
				{
					"name": "Empty Messages",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"gpt-5-nano\",\n  \"messages\": []\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				},
				{
					"name": "Invalid Temperature",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"gpt-5-nano\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Test\"\n    }\n  ],\n  \"temperature\": 5.0\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				},
				{
					"name": "Invalid Provider Priority",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "Content-Type",
								"value": "application/json"
							},
							{
								"key": "X-Provider-Priority",
								"value": "nonexistent-provider"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\n  \"model\": \"gpt-5-nano\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"This should use fallback provider.\"\n    }\n  ]\n}"
						},
						"url": {
							"raw": "{{base_url}}/v1/chat/completions",
							"host": [
								"{{base_url}}"
							],
							"path": [
								"v1",
								"chat",
								"completions"
							]
						}
					},
					"response": []
				}
			]
		}
	],
	"event": [
		{
			"listen": "prerequest",
			"script": {
				"type": "text/javascript",
				"exec": [
					"// Set request timestamp",
					"pm.globals.set('timestamp', new Date().toISOString());"
				]
			}
		},
		{
			"listen": "test",
			"script": {
				"type": "text/javascript",
				"exec": [
					"// Basic response validation",
					"pm.test('Response time is reasonable', function () {",
					"    pm.expect(pm.response.responseTime).to.be.below(30000);",
					"});",
					"",
					"pm.test('Response has correct content type', function () {",
					"    if (pm.response.code === 200) {",
					"        pm.expect(pm.response.headers.get('Content-Type')).to.include('application/json');",
					"    }",
					"});",
					"",
					"// Chat completion specific tests",
					"if (pm.request.url.path.includes('chat/completions') && pm.response.code === 200) {",
					"    pm.test('Chat completion response structure', function () {",
					"        const response = pm.response.json();",
					"        pm.expect(response).to.have.property('id');",
					"        pm.expect(response).to.have.property('object');",
					"        pm.expect(response).to.have.property('created');",
					"        pm.expect(response).to.have.property('model');",
					"        pm.expect(response).to.have.property('choices');",
					"        pm.expect(response).to.have.property('usage');",
					"        pm.expect(response.choices).to.be.an('array');",
					"        pm.expect(response.choices.length).to.be.greaterThan(0);",
					"    });",
					"}",
					"",
					"// Health check specific tests",
					"if (pm.request.url.path.includes('health') && pm.response.code === 200) {",
					"    pm.test('Health check response structure', function () {",
					"        const response = pm.response.json();",
					"        pm.expect(response).to.have.property('status');",
					"        pm.expect(response).to.have.property('timestamp');",
					"    });",
					"}"
				]
			}
		}
	],
	"variable": [
		{
			"key": "base_url",
			"value": "http://localhost:8000",
			"type": "string"
		}
	]
}